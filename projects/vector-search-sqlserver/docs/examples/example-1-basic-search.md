# Example 1: Basic Vector Search

**Part of:** [Vector Search in SQL Server](../../README.md)

## Overview

This example demonstrates a complete end-to-end vector search implementation: storing vectors, building LSH indexes, and performing similarity search.

## Prerequisites

- SQL Server 2016+ with CLR enabled
- dotex `OoBDev.Data.Vectors.DB` database project deployed
- Sample embedding vectors (384-dimensional from sentence transformer)

**Source Code:** [dotex OoBDev.Data.Vectors.DB](https://github.com/OutOfBandDevelopment/dotex/tree/687bd7d/src/Extensions/OoBDev.Data.Vectors.DB)

---

## Step 1: Setup Database

### Enable CLR

```sql
-- Enable CLR integration
EXEC sp_configure 'clr enabled', 1;
RECONFIGURE;
GO
```

### Deploy OoBDev.Data.Vectors Assembly

```sql
-- Deploy CLR assembly (SAFE permission set)
CREATE ASSEMBLY [OoBDev.Data.Vectors]
FROM 'C:\path\to\OoBDev.Data.Vectors.dll'
WITH PERMISSION_SET = SAFE;
GO

-- Create CLR types and functions
-- (Automatically created by DACPAC deployment)
```

### Verify Installation

```sql
-- Check CLR types
SELECT *
FROM sys.types
WHERE is_assembly_type = 1
    AND name LIKE 'Vector%';

-- Should return: VectorF, Vector, MatrixF, Matrix

-- Check CLR functions
SELECT
    OBJECT_NAME(object_id) AS FunctionName,
    type_desc
FROM sys.objects
WHERE type IN ('FS', 'FT', 'AF')  -- Scalar, Table, Aggregate
    AND SCHEMA_NAME(schema_id) = 'embedding';
```

---

## Step 2: Generate Random Hyperplanes

Hyperplanes are used to project vectors into binary hash codes.

```sql
-- Create a hash plane set (16-bit hash)
DECLARE @HashSetID INT = 1;
DECLARE @Dimensions INT = 384;  -- Sentence transformer dimensions
DECLARE @BitCount INT = 16;     -- 16-bit hash (65,536 possible values)

-- Generate random hyperplanes
DECLARE @PlaneID INT = 1;

WHILE @PlaneID <= @BitCount
BEGIN
    -- Generate random vector (uniform distribution)
    DECLARE @RandomVector embedding.VectorF =
        embedding.UniformF(@Dimensions, -1.0, 1.0, CHECKSUM(NEWID()));

    -- Store hyperplane
    INSERT INTO embedding.HashPlanes (HashPlaneID, Value, Dimensions, CreatedDate)
    VALUES (@PlaneID, @RandomVector, @Dimensions, GETDATE());

    -- Add to hash set
    INSERT INTO embedding.HashPlaneSets (HashSetID, HashPlaneID, Position)
    VALUES (@HashSetID, @PlaneID, @PlaneID);

    SET @PlaneID = @PlaneID + 1;
END;

-- Verify
SELECT
    hps.HashSetID,
    hps.Position,
    hp.Dimensions,
    CAST(hp.Value AS NVARCHAR(100)) AS HyperplanePreview
FROM embedding.HashPlaneSets hps
INNER JOIN embedding.HashPlanes hp ON hp.HashPlaneID = hps.HashPlaneID
WHERE hps.HashSetID = @HashSetID
ORDER BY hps.Position;
```

**Output:**
```
HashSetID | Position | Dimensions | HyperplanePreview
----------|----------|------------|-----------------------------------------
    1     |    1     |    384     | 0.234,-0.567,0.890,-0.123,0.456,...
    1     |    2     |    384     | -0.678,0.234,-0.890,0.567,-0.234,...
    ...
    1     |   16     |    384     | 0.123,-0.456,0.789,-0.234,0.567,...
```

**Source:** [HashPlanes Table](https://github.com/OutOfBandDevelopment/dotex/blob/687bd7d/src/Extensions/OoBDev.Data.Vectors.DB/Tables/embedding.HashPlanes.sql)

---

## Step 3: Store Sample Vectors

### Generate Sample Data

```sql
-- Sample documents (in real app, these would be from your data)
CREATE TABLE #SampleDocuments (
    DocumentID INT PRIMARY KEY,
    Title NVARCHAR(200),
    Content NVARCHAR(MAX),
    Embedding embedding.VectorF  -- Pre-computed from sentence transformer
);

INSERT INTO #SampleDocuments (DocumentID, Title, Content, Embedding)
VALUES
    (1, 'SQL Server Performance',
     'Optimizing SQL Server performance with indexes and query tuning.',
     '0.234,-0.456,0.789,...'),  -- 384 float values

    (2, 'Database Indexing',
     'Understanding clustered and non-clustered indexes in SQL Server.',
     '0.245,-0.445,0.792,...'),  -- Similar vector to doc 1

    (3, 'Machine Learning Basics',
     'Introduction to machine learning and neural networks.',
     '-0.567,0.890,-0.123,...'),  -- Different topic

    (4, 'Vector Databases',
     'Building vector search engines for semantic search applications.',
     '0.123,-0.234,0.567,...'),

    (5, 'Natural Language Processing',
     'NLP techniques for text understanding and generation.',
     '-0.678,0.345,-0.890,...');

-- In production, embeddings would be generated by:
-- - OpenAI API: text-embedding-3-small, text-embedding-3-large
-- - Sentence Transformers: all-MiniLM-L6-v2 (384 dims)
-- - Custom ONNX model: AllMiniLML6v2Sharp from dotex
```

### Store Vectors

```sql
-- Insert vectors into storage
INSERT INTO embedding.Vectors (Value, SourceID, Metadata, CreatedDate)
SELECT
    Embedding,
    DocumentID,
    CAST((SELECT Title AS [title], Content AS [content]
          FOR JSON PATH, WITHOUT_ARRAY_WRAPPER) AS NVARCHAR(MAX)),
    GETDATE()
FROM #SampleDocuments;

-- Verify
SELECT
    VectorID,
    SourceID,
    Metadata,
    CAST(Value AS NVARCHAR(100)) AS VectorPreview,
    CreatedDate
FROM embedding.Vectors;
```

**Output:**
```
VectorID | SourceID | Metadata                       | VectorPreview
---------|----------|--------------------------------|----------------------
    1    |    1     | {"title":"SQL Server..."}      | 0.234,-0.456,0.789...
    2    |    2     | {"title":"Database Indexing"}  | 0.245,-0.445,0.792...
    3    |    3     | {"title":"Machine Learning"}   | -0.567,0.890,-0.123...
    4    |    4     | {"title":"Vector Databases"}   | 0.123,-0.234,0.567...
    5    |    5     | {"title":"Natural Language"}   | -0.678,0.345,-0.890...
```

**Source:** [Vectors Table](https://github.com/OutOfBandDevelopment/dotex/blob/687bd7d/src/Extensions/OoBDev.Data.Vectors.DB/Tables/embedding.Vectors.sql)

---

## Step 4: Build LSH Hashes

```sql
-- Build hashes for all vectors
EXEC embedding.[oobdev://embedding/storage/hashes/build];

-- Verify hashes
SELECT
    h.VectorID,
    v.SourceID,
    h.Hash,
    h.HashSetID,
    -- Show hash in binary for understanding
    CAST(h.Hash AS BINARY(2)) AS HashBinary
FROM embedding.Hashes h
INNER JOIN embedding.Vectors v ON v.VectorID = h.VectorID
ORDER BY h.Hash;
```

**Output:**
```
VectorID | SourceID | Hash  | HashSetID | HashBinary
---------|----------|-------|-----------|-------------
    1    |    1     | 45321 | 1         | 0xB109
    2    |    2     | 45322 | 1         | 0xB10A  ← Similar hash!
    4    |    4     | 23456 | 1         | 0x5BA0
    3    |    3     | 12789 | 1         | 0x31F5
    5    |    5     | 8901  | 1         | 0x22C5
```

**Note:** Documents 1 and 2 have similar hashes (45321 vs 45322), indicating they are semantically similar!

**Source:** [EmbeddingStorageHashesBuild.sql](https://github.com/OutOfBandDevelopment/dotex/blob/687bd7d/src/Extensions/OoBDev.Data.Vectors.DB/Programmability/Stored%20Procedures/EmbeddingStorageHashesBuild.sql)

---

## Step 5: Perform Vector Search

### Query: Find Similar Documents

```sql
-- Search query: "SQL database optimization"
DECLARE @QueryText NVARCHAR(MAX) = 'SQL database optimization';

-- In production, generate embedding from query text:
-- @QueryVector = CallEmbeddingAPI(@QueryText)

-- For this example, use a vector similar to Document 1
DECLARE @QueryVector embedding.VectorF = '0.240,-0.450,0.785,...';

-- Compute query hash
DECLARE @QueryHash INT;

SELECT @QueryHash = SUM(
    CASE
        WHEN hp.Value.DotProduct(@QueryVector) < 0 THEN 0
        ELSE POWER(2, hps.Position-1)
    END)
FROM embedding.HashPlaneSets hps
INNER JOIN embedding.HashPlanes hp ON hp.HashPlaneID = hps.HashPlaneID
WHERE hps.HashSetID = 1;

-- @QueryHash = 45320 (close to documents 1 and 2)

-- Search with Hamming distance threshold
DECLARE @HammingDistance INT = 2;  -- Allow 2-bit difference
DECLARE @TopK INT = 3;

-- Phase 1: Find candidates using LSH (fast)
WITH Candidates AS (
    SELECT DISTINCT
        h.VectorID,
        h.Hash,
        dbo.HammingDistance(h.Hash, @QueryHash) AS HammingDist
    FROM embedding.Hashes h
    WHERE h.HashSetID = 1
        AND dbo.HammingDistance(h.Hash, @QueryHash) <= @HammingDistance
)
-- Phase 2: Compute exact distances (accurate)
SELECT TOP (@TopK)
    v.VectorID,
    v.SourceID,
    JSON_VALUE(v.Metadata, '$.title') AS Title,
    JSON_VALUE(v.Metadata, '$.content') AS Content,
    c.Hash,
    c.HammingDist,
    v.Value.CosineSimilarity(@QueryVector) AS Similarity,
    1 - v.Value.CosineSimilarity(@QueryVector) AS Distance
FROM embedding.Vectors v
INNER JOIN Candidates c ON c.VectorID = v.VectorID
ORDER BY Similarity DESC;
```

**Output:**
```
VectorID | SourceID | Title                    | Similarity | Distance | HammingDist
---------|----------|--------------------------|------------|----------|-------------
    1    |    1     | SQL Server Performance   |   0.987    |  0.013   |      1
    2    |    2     | Database Indexing        |   0.945    |  0.055   |      2
    4    |    4     | Vector Databases         |   0.823    |  0.177   |      2
```

**Interpretation:**
- Document 1 is most similar (0.987 similarity)
- Document 2 is also relevant (0.945 similarity)
- Document 4 is somewhat related (0.823 similarity)
- Documents 3 and 5 were filtered out (Hamming distance > 2)

---

## Step 6: Verify with Brute Force (Ground Truth)

Compare LSH results with exhaustive search:

```sql
-- Brute force: compute distance to ALL vectors
SELECT TOP 3
    v.VectorID,
    v.SourceID,
    JSON_VALUE(v.Metadata, '$.title') AS Title,
    v.Value.CosineSimilarity(@QueryVector) AS Similarity
FROM embedding.Vectors v
ORDER BY Similarity DESC;
```

**Output:**
```
VectorID | SourceID | Title                    | Similarity
---------|----------|--------------------------|------------
    1    |    1     | SQL Server Performance   |   0.987
    2    |    2     | Database Indexing        |   0.945
    4    |    4     | Vector Databases         |   0.823
```

**Result:** LSH search found the same top 3 documents as brute force! ✓

**Performance Comparison:**
- LSH: 3 distance calculations (only candidates)
- Brute Force: 5 distance calculations (all vectors)
- Speedup: 1.67x (modest for 5 vectors, but scales to 100x+ for millions)

---

## Complete Search Function

### Create Reusable Stored Procedure

```sql
CREATE OR ALTER PROCEDURE embedding.SearchSimilar
    @QueryVector embedding.VectorF,
    @TopK INT = 10,
    @HammingDistance INT = 4,
    @HashSetID INT = 1
AS
BEGIN
    SET NOCOUNT ON;

    -- Compute query hash
    DECLARE @QueryHash INT;

    SELECT @QueryHash = SUM(
        CASE
            WHEN hp.Value.DotProduct(@QueryVector) < 0 THEN 0
            ELSE POWER(2, hps.Position-1)
        END)
    FROM embedding.HashPlaneSets hps
    INNER JOIN embedding.HashPlanes hp ON hp.HashPlaneID = hps.HashPlaneID
    WHERE hps.HashSetID = @HashSetID;

    -- Search using LSH + exact distance
    WITH Candidates AS (
        SELECT DISTINCT h.VectorID
        FROM embedding.Hashes h
        WHERE h.HashSetID = @HashSetID
            AND dbo.HammingDistance(h.Hash, @QueryHash) <= @HammingDistance
    )
    SELECT TOP (@TopK)
        v.VectorID,
        v.SourceID,
        v.Metadata,
        v.Value.CosineSimilarity(@QueryVector) AS Similarity,
        1 - v.Value.CosineSimilarity(@QueryVector) AS Distance
    FROM embedding.Vectors v
    INNER JOIN Candidates c ON c.VectorID = v.VectorID
    ORDER BY Similarity DESC;
END;
GO
```

### Usage

```sql
-- Simple search call
EXEC embedding.SearchSimilar
    @QueryVector = '0.240,-0.450,0.785,...',
    @TopK = 5,
    @HammingDistance = 3;
```

---

## C# Integration

### ADO.NET Example

```csharp
using System.Data.SqlClient;
using System.Data;

public class VectorSearchService
{
    private readonly string _connectionString;

    public async Task<List<SearchResult>> SearchSimilarAsync(
        float[] queryVector, int topK = 10, int hammingDistance = 4)
    {
        using (var connection = new SqlConnection(_connectionString))
        {
            await connection.OpenAsync();

            using (var command = new SqlCommand(
                "embedding.SearchSimilar", connection))
            {
                command.CommandType = CommandType.StoredProcedure;

                // Convert float[] to binary
                byte[] vectorBytes = ConvertVectorToBytes(queryVector);

                command.Parameters.AddWithValue("@QueryVector", vectorBytes);
                command.Parameters.AddWithValue("@TopK", topK);
                command.Parameters.AddWithValue("@HammingDistance", hammingDistance);

                var results = new List<SearchResult>();

                using (var reader = await command.ExecuteReaderAsync())
                {
                    while (await reader.ReadAsync())
                    {
                        results.Add(new SearchResult
                        {
                            VectorID = reader.GetInt64(0),
                            SourceID = reader.GetInt64(1),
                            Metadata = reader.GetString(2),
                            Similarity = reader.GetDouble(3),
                            Distance = reader.GetDouble(4)
                        });
                    }
                }

                return results;
            }
        }
    }

    private byte[] ConvertVectorToBytes(float[] vector)
    {
        byte[] bytes = new byte[vector.Length * sizeof(float)];
        Buffer.BlockCopy(vector, 0, bytes, 0, bytes.Length);
        return bytes;
    }
}

public class SearchResult
{
    public long VectorID { get; set; }
    public long SourceID { get; set; }
    public string Metadata { get; set; }
    public double Similarity { get; set; }
    public double Distance { get; set; }
}
```

---

## Performance Tuning

### Adjust Hamming Distance

**Trade-off: Recall vs Speed**

```sql
-- Tight threshold (fast, may miss results)
@HammingDistance = 1  -- Only 1-bit difference

-- Balanced (recommended)
@HammingDistance = 3  -- Up to 3-bit difference

-- Loose threshold (slower, high recall)
@HammingDistance = 5  -- Up to 5-bit difference
```

**Candidate Set Size by Hamming Distance:**

| Hamming Distance | Candidate Set (1M vectors, 16-bit hash) | Recall |
|------------------|----------------------------------------|--------|
| 0 | ~15 vectors | 60% |
| 1 | ~250 vectors | 75% |
| 2 | ~2,000 vectors | 85% |
| 3 | ~12,000 vectors | 92% |
| 4 | ~50,000 vectors | 96% |
| 5 | ~150,000 vectors | 98% |

### Increase Hash Bits

**More bits = Better precision**

```sql
-- 8-bit hash (256 buckets)
@BitCount = 8   -- Fast, low precision

-- 16-bit hash (65,536 buckets) - recommended
@BitCount = 16  -- Balanced

-- 32-bit hash (4B buckets)
@BitCount = 32  -- High precision, slower hash building
```

---

## Next Steps

- [Example 2: Async Processing](example-2-async-processing.md) - Service Broker integration
- [Example 3: Hybrid Search](example-3-hybrid-search.md) - LSH + exact refinement
- [Data Flows](../data-flows.md) - Understanding the search flow
- [Architecture](../architecture.md) - Design patterns

---

## External References

**Source Code:**
- [Complete Implementation](https://github.com/OutOfBandDevelopment/dotex/tree/687bd7d/src/Extensions/OoBDev.Data.Vectors.DB)
- [Example Scripts](https://github.com/OutOfBandDevelopment/dotex/tree/687bd7d/src/Extensions/OoBDev.Data.Vectors/ExampleScripts)

---

*Last updated: 2026-01-09*
*dotex commit: 687bd7d*
